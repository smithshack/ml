#tenflow general

import pandas as pd
import numpy as np
import tensorflow as tf
from tensorflow.keras import layers, models
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
import matplotlib.pyplot as plt


# Load the dataset
url = "auto-mpg.csv"  # Replace with your CSV file path
column_names = ['MPG', 'Cylinders', 'Displacement', 'Horsepower', 'Weight', 'Acceleration', 'Model Year', 'Origin']
dataset = pd.read_csv(url, names=column_names, na_values='?', comment='\t', sep=',', skipinitialspace=True)


dataset.info()

dataset.describe()

dataset.head()

# Drop rows with missing values
dataset = dataset.dropna()

# Convert columns to appropriate numeric data types
for column in ['MPG', 'Cylinders', 'Displacement', 'Horsepower', 'Weight', 'Acceleration', 'Model Year']:
    dataset[column] = pd.to_numeric(dataset[column], errors='coerce')

# Check for NaN values in the dataset
print("NaN values before dropping: \n", dataset.isnull().sum())

# Drop any rows with NaN values
dataset = dataset.dropna()

# Check again for NaN values to confirm
print("NaN values after dropping: \n", dataset.isnull().sum())

# Convert 'Origin' to string for one-hot encoding
dataset['Origin'] = dataset['Origin'].astype(str)

# Convert categorical 'Origin' column to one-hot encoding
dataset = pd.get_dummies(dataset, columns=['Origin'], prefix='', prefix_sep='')


# Split the dataset into training and testing sets
train_dataset, test_dataset = train_test_split(dataset, test_size=0.2, random_state=42)

# Separate features and labels
train_features = train_dataset.copy()
test_features = test_dataset.copy()
train_labels = train_features.pop('MPG')
test_labels = test_features.pop('MPG')

# Check for NaN values in the dataset
assert not train_features.isnull().any().any(), "There are NaN values in the training features"
assert not test_features.isnull().any().any(), "There are NaN values in the test features"
assert not train_labels.isnull().any(), "There are NaN values in the training labels"
assert not test_labels.isnull().any(), "There are NaN values in the test labels"


# Normalize the features
scaler = StandardScaler()
train_features = scaler.fit_transform(train_features)
test_features = scaler.transform(test_features)




def build_model():
    model = models.Sequential([
        layers.Dense(64, activation='relu', input_shape=[train_features.shape[1]]),
        layers.Dense(64, activation='relu'),
        layers.Dense(1)
    ])
    return model

model = build_model()



model.compile(optimizer='adam',
              loss='mse',
              metrics=['mae', 'mse'])



history = model.fit(train_features, train_labels, 
                    epochs=100, validation_split=0.2, verbose=0)

# Plot training history
hist = pd.DataFrame(history.history)
hist['epoch'] = history.epoch

plt.figure(figsize=(12, 4))

plt.subplot(1, 2, 1)
plt.xlabel('Epoch')
plt.ylabel('Mean Abs Error [MPG]')
plt.plot(hist['epoch'], hist['mae'], label='Train Error')
plt.plot(hist['epoch'], hist['val_mae'], label='Val Error')
plt.legend()

plt.subplot(1, 2, 2)
plt.xlabel('Epoch')
plt.ylabel('Mean Square Error [MPG^2]')
plt.plot(hist['epoch'], hist['mse'], label='Train Error')
plt.plot(hist['epoch'], hist['val_mse'], label='Val Error')
plt.legend()

plt.show()


test_loss, test_mae, test_mse = model.evaluate(test_features, test_labels, verbose=2)
print(f'\nTest MAE: {test_mae:.2f} MPG')



test_predictions = model.predict(test_features).flatten()

plt.scatter(test_labels, test_predictions)
plt.xlabel('True Values [MPG]')
plt.ylabel('Predictions [MPG]')
plt.axis('equal')
plt.axis('square')
plt.plot([-100, 100], [-100, 100])
plt.show()

error = test_predictions - test_labels
plt.hist(error, bins=25)
plt.xlabel('Prediction Error [MPG]')
plt.ylabel('Count')
plt.show()



# Print predicted vs actual values
print("\nPredicted vs Actual MPG values:")
for predicted, actual in zip(test_predictions, test_labels):
print(f"Predicted: {predicted:.2f}, Actual: {actual:.2f}")


